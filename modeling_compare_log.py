# modeling_compare_log.py
import os, numpy as np, torch, matplotlib.pyplot as plt
from torch.utils.data import DataLoader, random_split
import args_new as new_args
from replay_fouling import ReplayMemory

plt.rcParams["figure.dpi"] = 160

MODEL   = "cartpole"                 # å¦‚æœè¦æ¢ç¯å¢ƒ æˆ‘éœ€è¦ä¿®æ”¹è¿™ä¸€æ¡
METHODS = ["mamba", "kovae"]         # ğŸ”¥MamKO vs KoVAEï¼ï¼ï¼
BATCH   = 128
VAL_RATIO = 0.2

def make_env():
    from envs.cartpole import CartPoleEnv_adv as dreamer
    return dreamer().unwrapped

def build_args(method: str, env):
    args = dict(new_args.args)
    args.update(new_args.ENV_PARAMS[MODEL])

    args["env"]     = MODEL
    args["method"]  = method
    args["control"] = False

    # å…ˆè¡¥é½ç»´åº¦ï¼ˆéå¸¸å…³é”®ï¼ŒMamKO åœ¨ __init__ é‡Œä¼šç”¨åˆ°ï¼‰
    args["state_dim"] = int(env.observation_space.shape[0])
    args["act_dim"]   = int(env.action_space.shape[0])
    args.setdefault("obs_dim", args["state_dim"])

    # è·¯å¾„å…œåº•
    fold = f"save_model/{method}/{MODEL}"
    os.makedirs(fold, exist_ok=True)
    args.setdefault("save_model_path", f"{fold}/model.pt")
    args.setdefault("save_opti_path",  f"{fold}/opti.pt")
    args.setdefault("shift_x",         f"{fold}/shift_x.txt")
    args.setdefault("scale_x",         f"{fold}/scale_x.txt")
    args.setdefault("shift_u",         f"{fold}/shift_u.txt")
    args.setdefault("scale_u",         f"{fold}/scale_u.txt")
    return args

def load_model(method: str, args):
    if method == "kovae":
        from kovae_model import Koopman_Desko
    elif method == "mamba":
        from MamKO import Koopman_Desko
    else:
        raise ValueError(f"Unknown method {method}")
    m = Koopman_Desko(args)

    # æ¢å¤æƒé‡
    if hasattr(m, "parameter_restore"): m.parameter_restore(args)
    elif hasattr(m, "restore"):         m.restore()

    # è®¾å¤‡ï¼šä¼˜å…ˆå·²æœ‰ deviceï¼Œå…¶æ¬¡ mps->cuda->cpu
    if hasattr(m, "device"):
        device = m.device
    elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")
    m.device = device

    # MamKO åªæœ‰ .netï¼Œåšä¸ªåˆ«åæ–¹ä¾¿å…œåº•ï¼
    if not hasattr(m, "model") and hasattr(m, "net"):
        m.model = m.net
    try:
        if hasattr(m, "model"):
            m.model.to(device)
    except Exception:
        pass
    return m

def _get_split_dataset(mem: ReplayMemory, split: str):
    if split == "train":
        return mem.dataset_train
    if split == "test":
        return mem.dataset_test
    if split == "val":
        if hasattr(mem, "dataset_val"):
            return mem.dataset_val
        # ä» train åˆ‡å‡º val
        full = mem.dataset_train
        n = len(full)
        n_val = max(1, int(round(VAL_RATIO * n)))
        n_train = max(1, n - n_val)
        g = torch.Generator().manual_seed(0)
        val_ds, _ = random_split(full, [n_val, n_train], generator=g)
        return val_ds
    raise ValueError(split)

@torch.no_grad()
def one_step_mse(model, args, env, split="val", batch_size=BATCH):
#  ä½¿ç”¨åºåˆ—æ•°æ® (x_seq, u_seq) è¯„ä¼° L æ­¥é¢„æµ‹çš„ MSEï¼ˆå¯¹é½åˆ°æœªæ¥çª—å£ï¼‰ã€‚
    - x_seq: [B, O+L, Dx]
    - u_seq: [B, O+L-1, Du]
    é¢„æµ‹ä¸çœŸå€¼éƒ½ç”¨åŒä¸€å½’ä¸€åŒ–ç©ºé—´æ¯”è¾ƒï¼Œä¾¿äºæ–¹æ³•é—´å…¬å¹³å¯¹æ¯”ã€‚
    
    O = int(args["old_horizon"])
    L = int(args["pred_horizon"])

    # å…³é”®ï¼špredict_evolution=True æ‰ä¼šè¿”å› (x_seq, u_seq)
    mem = ReplayMemory(args, env, predict_evolution=True)
    ds  = _get_split_dataset(mem, split)
    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)

    dev = model.device
    mse_sum = 0.0
    n_samp  = 0

    for x_seq, u_seq in loader:
        # x_seq: [B, O+L, Dx], u_seq: [B, O+L-1, Du]
        x_seq = x_seq.float().to(dev)
        u_seq = u_seq.float().to(dev)

        # æœªæ¥çœŸå€¼çª—å£ï¼š[B, L, Dx]
        y_true = x_seq[:, O:O+L, :].detach().cpu().numpy()

        # åˆ†æ–¹æ³•è·å–é¢„æµ‹åºåˆ—
        y_pred = None
        if hasattr(model, "net"):  # MamKO
            loss, y_pred_seq = model.net(x_seq, u_seq)   # loss æ ‡é‡, y_pred_seq: [L, B, Dx]ï¼ˆè§ selective_scanï¼‰
            y_pred = np.transpose(y_pred_seq, (1, 0, 2)) # -> [B, L, Dx]
        else:
            # KoVAE å£³ï¼šæ‹¼æ¥ xinï¼Œå†è¿‡ self.model å¾— xhatï¼ˆé•¿åº¦ä¸ x_seq ç›¸åŒï¼‰
            if hasattr(model, "_make_batch"):
                x, u, xin = model._make_batch((x_seq, u_seq))
            else:
                # å…œåº•ï¼šåªç”¨ x
                xin = x_seq
            # å–å‡º Î±Î²Î³ï¼›è‹¥æ²¡æœ‰å°±å…¨ 0
            alpha = float(getattr(model, "alpha", 0.0))
            beta  = float(getattr(model, "beta",  0.0))
            gamma = float(getattr(model, "gamma", 0.0))
            loss, xhat, _ = model.model(xin, alpha, beta, gamma)  # xhat: [B, O+L, Dx]
            y_pred = xhat[:, O:O+L, :].detach().cpu().numpy()

        if y_pred is None:
            raise RuntimeError("Failed to obtain prediction sequence from the model.")

        # [B, L, Dx] â†’ per-sample MSE
        err = ((y_pred - y_true) ** 2).reshape(y_true.shape[0], -1).mean(axis=1)
        mse_sum += float(err.sum())
        n_samp  += int(err.shape[0])

    return mse_sum / max(1, n_samp)

def plot_log_bar(method2val, title, outpng):
    methods = list(method2val.keys())
    vals = [method2val[m] for m in methods]
    plt.figure()
    plt.yscale("log")
    plt.bar(methods, vals)
    plt.ylabel("MSE (log scale)")
    plt.title(title)
    for i, v in enumerate(vals):
        if np.isfinite(v):
            plt.text(i, v, f"{v:.3e}", ha="center", va="bottom", rotation=90, fontsize=8)
    os.makedirs(os.path.dirname(outpng), exist_ok=True)
    plt.tight_layout()
    plt.savefig(outpng)
    plt.close()

def main():
    outdir = f"results/{MODEL}/compare"
    os.makedirs(outdir, exist_ok=True)

    env = make_env()

    for split in ["train", "val", "test"]:
        summary = {}
        for m in METHODS:
            args   = build_args(m, env)   # å…ˆç”¨ env è¡¥å¥½ç»´åº¦
            model  = load_model(m, args)  # å†å®ä¾‹åŒ–ï¼ˆMamKO éœ€è¦ï¼‰
            summary[m] = one_step_mse(model, args, env, split=split)
        plot_log_bar(summary, f"Modeling {split} MSE", f"{outdir}/modeling_{split}_log.png")
        print(split, {k: f"{v:.3e}" for k, v in summary.items()})

if __name__ == "__main__":
    main()

